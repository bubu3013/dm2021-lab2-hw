{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:嚴幼珊\n",
    "\n",
    "Student ID: 110062531\n",
    "\n",
    "GitHub ID: bubu3013\n",
    "\n",
    "Kaggle name: Silvia Yen\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](img/pic0.png)\n",
    "![pic0](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2021-Lab2-master Repo](https://github.com/fhcalderon87/DM2021-Lab2-master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/c/dm2021-lab2-hw2/) regarding Emotion Recognition on Twitter. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "    Submit your last submission __BEFORE the deadline (Dec. 24th 11:59 pm, Friday)__. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Dec. 29th 11:59 pm, Wednesday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Begin Assignment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Lab 2\n",
    "In this lab session we will focus on the use of Neural Word Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. Data preparation\n",
    "2. Feature engineering\n",
    "3. Model\n",
    "4. Results evaluation\n",
    "5. Other things you could try\n",
    "6. Deep Learning\n",
    "7. Word to Vector\n",
    "8. Clustering\n",
    "9. High-dimension Visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Library Requirements:\n",
    "\n",
    "#### Same as Lab1:\n",
    "- [Jupyter](http://jupyter.org/) (Strongly recommended but not required)\n",
    "    - Install via `pip3 install jupyter` and use `jupyter notebook` in terminal to run\n",
    "- [Scikit Learn](http://scikit-learn.org/stable/index.html)\n",
    "    - Install via `pip3 sklearn` from a terminal\n",
    "- [Pandas](http://pandas.pydata.org/)\n",
    "    - Install via `pip3 install pandas` from a terminal\n",
    "- [Numpy](http://www.numpy.org/)\n",
    "    - Install via `pip3 install numpy` from a terminal\n",
    "- [Matplotlib](https://matplotlib.org/)\n",
    "    - Install via `pip3 maplotlib` from a terminal\n",
    "- [Plotly](https://plot.ly/)\n",
    "    - Install via `pip3 install plotly` from a terminal\n",
    "- [Seaborn](https://seaborn.pydata.org/)\n",
    "    - Install and signup for `seaborn`\n",
    "- [NLTK](http://www.nltk.org/)\n",
    "    - Install via `pip3 install nltk` from a terminal\n",
    "    \n",
    "#### New Libraries to intsall:\n",
    "- [Gensim](https://pypi.org/project/gensim/)\n",
    "    - Install via `pip3 install gensim`\n",
    "\n",
    "- [Keras](https://keras.io/)\n",
    "    - Install via `pip3 install keras`\n",
    "    \n",
    "                                                                                            \n",
    "                                                                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset:** [SemEval 2017 Task](https://competitions.codalab.org/competitions/16380)\n",
    "\n",
    "**Task:** Classify text data into 4 different emotions using word embedding and other deep information retrieval approaches.\n",
    "\n",
    "![pic0](pics/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before beggining the lab, please make sure to download the [Google News Dataset](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit) and place it in a folder named \"GoogleNews\" in the same directory as this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load data\n",
    "\n",
    "We start by loading the csv files into a single pandas dataframe for training and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "### training data\n",
    "anger_train = pd.read_csv(\"data/semeval/train/anger-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None,names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_train = pd.read_csv(\"data/semeval/train/sadness-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_train = pd.read_csv(\"data/semeval/train/fear-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_train = pd.read_csv(\"data/semeval/train/joy-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combine 4 sub-dataset\n",
    "# concatenate\n",
    "train_df = pd.concat([anger_train, fear_train, joy_train, sadness_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text emotion  intensity\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....   anger      0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...   anger      0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...   anger      0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...   anger      0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...   anger      0.896"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### testing data\n",
    "anger_test = pd.read_csv(\"data/semeval/dev/anger-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_test = pd.read_csv(\"data/semeval/dev/sadness-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_test = pd.read_csv(\"data/semeval/dev/fear-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_test = pd.read_csv(\"data/semeval/dev/joy-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "\n",
    "# combine 4 sub-dataset\n",
    "test_df = pd.concat([anger_test, fear_test, joy_test, sadness_test], ignore_index=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "train_df = train_df.sample(frac=1)#do the complete dataset\n",
    "test_df = test_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training df:  (3613, 4)\n",
      "Shape of Testing df:  (347, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Training df: \", train_df.shape)\n",
    "print(\"Shape of Testing df: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 1 (Take home): **  \n",
    "Plot word frequency for Top 30 words in both train and test dataset. (Hint: refer to DM lab 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_N = 30\n",
    "\n",
    "word_dist = nltk.FreqDist(train_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_frequenct = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_frequency = train_df.text.str.split(expand=True).stack().value_counts()\n",
    "word_frequency = word_frequency[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save a list of word_frequency's index\n",
    "x_label = word_frequency.index\n",
    "y_label = word_frequency.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reference: \n",
    "# https://vimsky.com/zh-tw/examples/usage/matplotlib-pyplot-hist-in-python.html\n",
    "# https://www.delftstack.com/zh-tw/howto/matplotlib/set-x-axis-values-matplotlib/\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# draw a histogram\n",
    "# 調整y軸大小\n",
    "# 調整x字的方向\n",
    "\n",
    "plt.bar(x_label,y_label, tick_label=x_label)\n",
    "plt.xticks(x_label,word_frequency.index)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_N = 30\n",
    "\n",
    "word_dist = nltk.FreqDist(test_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_frequenct = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_frequency = test_df.text.str.split(expand=True).stack().value_counts()\n",
    "word_frequency = word_frequency[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save a list of word_frequency's index\n",
    "x_label = word_frequency.index\n",
    "y_label = word_frequency.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reference: \n",
    "# https://vimsky.com/zh-tw/examples/usage/matplotlib-pyplot-hist-in-python.html\n",
    "# https://www.delftstack.com/zh-tw/howto/matplotlib/set-x-axis-values-matplotlib/\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# draw a histogram\n",
    "# 調整y軸大小\n",
    "# 調整x字的方向\n",
    "\n",
    "plt.bar(x_label,y_label, tick_label=x_label)\n",
    "plt.xticks(x_label,word_frequency.index)\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.2 Save data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save our data in Pickle format. The pickle module implements binary protocols for serializing and de-serializing a Python object structure.   \n",
    "  \n",
    "Some advantages for using pickle structure:  \n",
    "* Because it stores the attribute type, it's more convenient for cross-platform use.  \n",
    "* When your data is huge, it could use less space to store also consume less loading time.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## save to pickle file\n",
    "## if the data is big, pickle is efficient\n",
    "train_df.to_pickle(\"train_df.pkl\") \n",
    "test_df.to_pickle(\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "## load a pickle file\n",
    "train_df = pd.read_pickle(\"train_df.pkl\")\n",
    "test_df = pd.read_pickle(\"test_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information: https://reurl.cc/0Dzqx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1.3 Exploratory data analysis (EDA)\n",
    "\n",
    "Again, before getting our hands dirty, we need to explore a little bit and understand the data we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_df.groupby(['emotion']).size(): with NaN\n",
    "# train_df.groupby(['emotion']).count(): without NaN\n",
    "# train_df.groupby(['emotion']).mean(): get the mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "anger       857\n",
       "fear       1147\n",
       "joy         823\n",
       "sadness     786\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group to find distribution\n",
    "train_df.groupby(['emotion']).count()['text'] # groupby: 根據某些條件將數據分成幾組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the histogram of the data\n",
    "labels = train_df['emotion'].unique() #處理DataFrame的單列時使用，並返回一列的所有唯一元素\n",
    "post_total = len(train_df)\n",
    "df1 = train_df.groupby(['emotion']).count()['text']\n",
    "df1 = df1.apply(lambda x: round(x*100/post_total,3)) #lamba: 匿名函式, round(x):DataFrame四捨五入到小數位數x\n",
    "\n",
    "#plot\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "plt.bar(df1.index,df1.values)\n",
    "\n",
    "#arrange\n",
    "plt.ylabel('% of instances')\n",
    "plt.xlabel('Emotion')\n",
    "plt.title('Emotion distribution')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature engineering\n",
    "### Using Bag of Words\n",
    "Using scikit-learn ```CountVectorizer``` perform word frequency and use these as features to train a model.  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# build analyzers (bag-of-words)\n",
    "BOW_vectorizer = CountVectorizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Learn a vocabulary dictionary of all tokens in the raw documents.\n",
    "BOW_vectorizer.fit(train_df['text']) #.fit():算均值，平方差啊，最大/小值。可以理解為一個訓練過程。\n",
    "# 2. Transform documents to document-term matrix.\n",
    "train_data_BOW_features = BOW_vectorizer.transform(train_df['text']) #.transform():在Fit的基礎上，進行標準化，降維，歸一化等操作\n",
    "test_data_BOW_features = BOW_vectorizer.transform(test_df['text'])   # fit_transform() = fit() + transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3613x10115 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 51467 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "train_data_BOW_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data_BOW_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add .toarray() to show\n",
    "train_data_BOW_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3613, 10115)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dimension\n",
    "train_data_BOW_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2k17', '2much', '2nd', '30', '300', '301', '30am', '30pm', '30s', '31']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe some feature names\n",
    "feature_names = BOW_vectorizer.get_feature_names() # get the values of the cols\n",
    "feature_names[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding is done. We can technically feed this into our model. However, depending on the embedding technique you use and your model, your accuracy might not be as high, because:\n",
    "\n",
    "* curse of dimensionality  (we have 10,115 dimension now)\n",
    "* some important features are ignored (for example, some models using emoticons yeld better performance than counterparts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"😂\" in feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try using another tokenizer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Silvia\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3613, 500)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# build analyzers (bag-of-words)\n",
    "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize) \n",
    "\n",
    "# apply analyzer to training data\n",
    "# fit to learn the token\n",
    "BOW_500.fit(train_df['text'])\n",
    "\n",
    "train_data_BOW_features_500 = BOW_500.transform(train_df['text'])\n",
    "\n",
    "## check dimension\n",
    "train_data_BOW_features_500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [4, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_BOW_features_500.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['change',\n",
       " 'cheer',\n",
       " 'cheerful',\n",
       " 'cheerfully',\n",
       " 'cheering',\n",
       " 'cheery',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'could',\n",
       " 'country']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# observe some feature names\n",
    "feature_names_500 = BOW_500.get_feature_names()\n",
    "feature_names_500[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"😂\" in feature_names_500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 2 (Take home): **  \n",
    "Generate an embedding using the TF-IDF vectorizer instead of th BOW one with 1000 features and show the feature names for features [100:110]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['change',\n",
       " 'cheer',\n",
       " 'cheerful',\n",
       " 'cheerfully',\n",
       " 'cheering',\n",
       " 'cheery',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'could',\n",
       " 'country']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer here\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF\n",
    "TFIDF_1000 = TfidfVectorizer(max_features=1000)\n",
    "# 1. Learn a vocabulary dictionary of all tokens in the raw documents.\n",
    "TFIDF_1000.fit(train_df['text'])\n",
    "# 2. Transform documents to document-term matrix.\n",
    "train_data_TFIDF_features_1000 = TFIDF_1000.transform(train_df['text'])\n",
    "\n",
    "feature_names_1000 = TFIDF_1000.get_feature_names()\n",
    "feature_names_500[100:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTF-IDF 做了以下這樣的假設：\\n一個『詞彙』越常出現在一篇『文件』中，這個『詞彙』越重要\\n一個『詞彙』越常出現在多篇『文件』中，這個『詞彙』越不重要\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TF-IDF 做了以下這樣的假設：\n",
    "一個『詞彙』越常出現在一篇『文件』中，這個『詞彙』越重要\n",
    "一個『詞彙』越常出現在多篇『文件』中，這個『詞彙』越不重要\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Model\n",
    "### 3.1 Decision Trees\n",
    "Using scikit-learn ```DecisionTreeClassifier``` performs word frequency and uses these as features to train a model.  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (3613, 500)\n",
      "y_train.shape:  (3613,)\n",
      "X_test.shape:  (347, 500)\n",
      "y_test.shape:  (347,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# for a classificaiton problem, you need to provide both training & testing data\n",
    "X_train = BOW_500.transform(train_df['text'])\n",
    "y_train = train_df['emotion']\n",
    "\n",
    "X_test = BOW_500.transform(test_df['text'])\n",
    "y_test = test_df['emotion']\n",
    "\n",
    "## take a look at data dimension is a good habbit  :)\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'fear', 'joy', 'sadness', 'fear', 'sadness', 'fear', 'joy',\n",
       "       'sadness', 'fear'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build DecisionTree model\n",
    "DT_model = DecisionTreeClassifier(random_state=0) \n",
    "# https://www.twblogs.net/a/5c2f92c7bd9eee35b3a4b63e\n",
    "\n",
    "## training!\n",
    "DT_model = DT_model.fit(X_train, y_train)\n",
    "# fit(x, y, batch_size, ...)\n",
    "# https://blog.csdn.net/qq_41617848/article/details/99969963\n",
    "\n",
    "## predict!\n",
    "y_train_pred = DT_model.predict(X_train)\n",
    "y_test_pred = DT_model.predict(X_test)\n",
    "\n",
    "## so we get the pred result\n",
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Results Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will check the results of our model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.99\n",
      "testing accuracy: 0.66\n"
     ]
    }
   ],
   "source": [
    "## accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))\n",
    "print('testing accuracy: {}'.format(round(acc_test, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.63      0.65      0.64        84\n",
      "        fear       0.66      0.69      0.68       110\n",
      "         joy       0.70      0.68      0.69        79\n",
      "     sadness       0.65      0.59      0.62        74\n",
      "\n",
      "    accuracy                           0.66       347\n",
      "   macro avg       0.66      0.66      0.66       347\n",
      "weighted avg       0.66      0.66      0.66       347\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## precision, recall, f1-score,\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_test_pred))\n",
    "# (classification_report(y_true, y_pred, target_names=target_names))\n",
    "# https://www.cnblogs.com/178mz/p/8558435.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55 20  5  4]\n",
      " [16 76  8 10]\n",
      " [ 7  8 54 10]\n",
      " [ 9 11 10 44]]\n"
     ]
    }
   ],
   "source": [
    "## check by confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_test_pred) \n",
    "print(cm)\n",
    "\n",
    "# confusion_matrix(y_true, y_pred, labels=None, sample_weight=None)\n",
    "# y_true: 是樣本真實分類結果，y_pred: 是樣本預測分類結果\n",
    "# labels：是所給出的類別，通過這個可對類別進行選擇\n",
    "# sample_weight : 樣本權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Funciton for visualizing confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix',\n",
    "                          cmap=sns.cubehelix_palette(as_cmap=True)):\n",
    "    \"\"\"\n",
    "    This function is modified from: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    classes.sort()\n",
    "    tick_marks = np.arange(len(classes))    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels = classes,\n",
    "           yticklabels = classes,\n",
    "           title = title,\n",
    "           xlabel = 'True label',\n",
    "           ylabel = 'Predicted label')\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ylim_top = len(classes) - 0.5\n",
    "    plt.ylim([ylim_top, -.5])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot your confusion matrix\n",
    "my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
    "plot_confusion_matrix(cm, classes=my_tags, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 3 (Take home): **  \n",
    "Can you interpret the results above? What do they mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. What is a cufusion matrix?\\n    Compute confusion matrix to evaluate the accuracy of a classification.\\n    A confusion matrix  C(i,j) is equal to the number of observations \\n    known to be in group \\'i\" and predicted to be in group \"j\".\\n\\n    Take the number 14 for example. C(0,2)=C(anger, fear)\\n    There are 14 emotions labed as \"anger\" but predicted as \"fear\".\\n\\n    As the color become darker, the accuracy is higher.\\n\\n2. About Accuracy.\\n\\n    The accuracy is as following. \\n    The training accuracy: 0.99\\n    The testing accuracy: 0.66\\n\\n3. The precision and recall in anger, fear, joy and sadness.\\n              precision    recall  \\n\\n           anger       0.63      0.65 \\n            fear       0.66      0.69 \\n             joy       0.70      0.68  \\n         sadness       0.65      0.59 \\n    The joy has the highest presision and the fear has the highest recall.\\n    The anger has the lowest presision and the sadness has the lowest recall.\\n    \\n4. The overall training accuracy: 0.99, abd testing accuracy: 0.66. \\n   This is overfitting because model perform well in training data but poorly in testing data.\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer here\n",
    "#reference:https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "\"\"\"\n",
    "1. What is a cufusion matrix?\n",
    "    Compute confusion matrix to evaluate the accuracy of a classification.\n",
    "    A confusion matrix  C(i,j) is equal to the number of observations \n",
    "    known to be in group 'i\" and predicted to be in group \"j\".\n",
    "\n",
    "    Take the number 14 for example. C(0,2)=C(anger, fear)\n",
    "    There are 14 emotions labed as \"anger\" but predicted as \"fear\".\n",
    "\n",
    "    As the color become darker, the accuracy is higher.\n",
    "\n",
    "2. About Accuracy.\n",
    "\n",
    "    The accuracy is as following. \n",
    "    The training accuracy: 0.99\n",
    "    The testing accuracy: 0.66\n",
    "\n",
    "3. The precision and recall in anger, fear, joy and sadness.\n",
    "              precision    recall  \n",
    "\n",
    "           anger       0.63      0.65 \n",
    "            fear       0.66      0.69 \n",
    "             joy       0.70      0.68  \n",
    "         sadness       0.65      0.59 \n",
    "    The joy has the highest presision and the fear has the highest recall.\n",
    "    The anger has the lowest presision and the sadness has the lowest recall.\n",
    "    \n",
    "4. The overall training accuracy: 0.99, abd testing accuracy: 0.66. \n",
    "   This is overfitting because model perform well in training data but poorly in testing data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 4 (Take home): **  \n",
    "Build a model using a ```Naive Bayes``` model and train it. What are the testing results? \n",
    "\n",
    "*Reference*: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.79\n",
      "testing accuracy: 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.63      0.65      0.64        84\n",
      "        fear       0.73      0.77      0.75       110\n",
      "         joy       0.78      0.71      0.74        79\n",
      "     sadness       0.64      0.62      0.63        74\n",
      "\n",
      "    accuracy                           0.70       347\n",
      "   macro avg       0.70      0.69      0.69       347\n",
      "weighted avg       0.70      0.70      0.70       347\n",
      "\n",
      "[[55 15  5  9]\n",
      " [ 9 85  5 11]\n",
      " [11  6 56  6]\n",
      " [12 10  6 46]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer here\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "## build Naive Bayes model\n",
    "NB_model = MultinomialNB()\n",
    "# https://www.twblogs.net/a/5c2f92c7bd9eee35b3a4b63e\n",
    "\n",
    "## training!\n",
    "NB_model = NB_model.fit(X_train, y_train)\n",
    "# fit(x, y, batch_size, ...)\n",
    "# https://blog.csdn.net/qq_41617848/article/details/99969963\n",
    "\n",
    "## predict!\n",
    "y_train_pred = NB_model.predict(X_train)\n",
    "y_test_pred = NB_model.predict(X_test)\n",
    "\n",
    "## accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))\n",
    "print('testing accuracy: {}'.format(round(acc_test, 2)))\n",
    "\n",
    "## precision, recall, f1-score,\n",
    "print(classification_report(y_true=y_test, y_pred=y_test_pred))\n",
    "\n",
    "NB_cm = confusion_matrix(y_true=y_test, y_pred=y_test_pred) \n",
    "print(NB_cm)\n",
    "\n",
    "plot_confusion_matrix(NB_cm, classes=my_tags, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1.  About Accuracy.\\n\\n    The accuracy is as following. \\n    The training accuracy: 0.79\\n    The testing accuracy: 0.7\\n\\n2.  The precision and recall in anger, fear, joy and sadness.\\n\\n              precision    recall\\n\\n       anger       0.63      0.65  \\n        fear       0.73      0.77 \\n         joy       0.78      0.71\\n     sadness       0.64      0.62\\n    The joy has the highest presision and the fear has the highest recall.\\n    The anger has the lowest presision and the sadness has the lowest recall.\\n\\n3.  The overall training accuracy: 0.79, abd testing accuracy: 0.7. \\n    This is neither overfitting nor underfitting. The result is goold.\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer here\n",
    "# Analysis\n",
    "\"\"\"\n",
    "1.  About Accuracy.\n",
    "\n",
    "    The accuracy is as following. \n",
    "    The training accuracy: 0.79\n",
    "    The testing accuracy: 0.7\n",
    "\n",
    "2.  The precision and recall in anger, fear, joy and sadness.\n",
    "\n",
    "              precision    recall\n",
    "\n",
    "       anger       0.63      0.65  \n",
    "        fear       0.73      0.77 \n",
    "         joy       0.78      0.71\n",
    "     sadness       0.64      0.62\n",
    "    The joy has the highest presision and the fear has the highest recall.\n",
    "    The anger has the lowest presision and the sadness has the lowest recall.\n",
    "\n",
    "3.  The overall training accuracy: 0.79, abd testing accuracy: 0.7. \n",
    "    This is neither overfitting nor underfitting. The result is goold.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 5 (Take home): **  \n",
    "\n",
    "How do the results from the Naive Bayes model and the Decision Tree model compare? How do you interpret these differences? Use the theoretical background covered in class to try and explain these differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n1.  How do the results from the Naive Bayes model and the Decision Tree model compare?\\n    從Naive Bayes 跟Decision Tree model 結果比較寫出來\\n\\n    The accuracy of training data in the Naive Bayes is 0.79 abd the testing accuracy: 0.7.\\n    The accuracy of training data in the Decision Tree model is 0.99 and the testing accuracy: 0.66.\\n    Just as lectures say, decision tree tends to be overfitting. \\n    and Naive Bayes can perform well in most of cases.\\n\\n2.  How do you interpret these differences?\\nex. accuracy is the same but not the same in presision. 要預測哪種情緒用哪種model比較好? (presision, recall)\\n\\n    Now let's have a look at the presision and recall of each emotion.\\n    anger: the precision in the Naive Bayes model is 0.63 and the recall is 0.65.\\n           the precision in the Decision Tree model is 0.63 and the recall is 0.65 as well.\\n           So the two models has a very same results.\\n           \\n    fear:  the precision in the Naive Bayes model is 0.73 and the recall is 0.77.\\n           the precision in the Decision Tree model is 0.66 and the recall is 0.69.\\n           So the Naive Bayes model performs better in fear cases.\\n           \\n    joy:   the precision in the Naive Bayes model is 0.78 and the recall is 0.71.\\n           the precision in the Decision Tree model is 0.70 and the recall is 0.70.\\n           So the Naive Bayes model performs better in joy cases.\\n           \\n   sadness:the precision in the Naive Bayes model is 0.64 and the recall is 0.62.\\n           the precision in the Decision Tree model is 0.65 and the recall is 0.59.\\n           So the Decision Tree model has a higer precision but the Naive Bayes model has a higher recall.  \\n    Overall, the Naive Bayes model performs well in both fear and joy cases.\\n    the two model has similar results in anger and sadness cases.\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer here\n",
    "\"\"\"\n",
    "1.  How do the results from the Naive Bayes model and the Decision Tree model compare?\n",
    "    從Naive Bayes 跟Decision Tree model 結果比較寫出來\n",
    "\n",
    "    The accuracy of training data in the Naive Bayes is 0.79 abd the testing accuracy: 0.7.\n",
    "    The accuracy of training data in the Decision Tree model is 0.99 and the testing accuracy: 0.66.\n",
    "    Just as lectures say, decision tree tends to be overfitting. \n",
    "    and Naive Bayes can perform well in most of cases.\n",
    "\n",
    "2.  How do you interpret these differences?\n",
    "ex. accuracy is the same but not the same in presision. 要預測哪種情緒用哪種model比較好? (presision, recall)\n",
    "\n",
    "    Now let's have a look at the presision and recall of each emotion.\n",
    "    anger: the precision in the Naive Bayes model is 0.63 and the recall is 0.65.\n",
    "           the precision in the Decision Tree model is 0.63 and the recall is 0.65 as well.\n",
    "           So the two models has a very same results.\n",
    "           \n",
    "    fear:  the precision in the Naive Bayes model is 0.73 and the recall is 0.77.\n",
    "           the precision in the Decision Tree model is 0.66 and the recall is 0.69.\n",
    "           So the Naive Bayes model performs better in fear cases.\n",
    "           \n",
    "    joy:   the precision in the Naive Bayes model is 0.78 and the recall is 0.71.\n",
    "           the precision in the Decision Tree model is 0.70 and the recall is 0.70.\n",
    "           So the Naive Bayes model performs better in joy cases.\n",
    "           \n",
    "   sadness:the precision in the Naive Bayes model is 0.64 and the recall is 0.62.\n",
    "           the precision in the Decision Tree model is 0.65 and the recall is 0.59.\n",
    "           So the Decision Tree model has a higer precision but the Naive Bayes model has a higher recall.  \n",
    "    Overall, the Naive Bayes model performs well in both fear and joy cases.\n",
    "    the two model has similar results in anger and sadness cases.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Other things you can try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, there are several things you can try that will affect your results. In order to yield better results, you can experiment by: \n",
    "    * Trying different features (Feature engineering)\n",
    "        -Eg. Word2Vec,PCA,LDA,FastText, Clustering......\n",
    "    * Trying different models\n",
    "    * Analyzing your results and interpret them to improve your feature engineering/model building process\n",
    "    * Iterate through the steps above until finding a satisfying result\n",
    "Remember that you should also consider the task at hand and the model you'll feed the data to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Deep Learning\n",
    "\n",
    "We use [Keras](https://keras.io/) to be our deep learning framwork, and follow the [Model (functional API)](https://keras.io/models/model/) to build a Deep Neural Network (DNN) model. Keras runs with Tensorflow in the backend. It's a nice abstraction to start working with NN models. \n",
    "\n",
    "Because Deep Learning is a 1-semester course, we can't talk about each detail about it in the lab session. Here, we only provide a simple template about how to build & run a DL model successfully. You can follow this template to design your model.\n",
    "\n",
    "We will begin by building a fully connected network, which looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fully Connected Network](pics/pic1.png)\n",
    "\n",
    "(source: https://github.com/drewnoff/spark-notebook-ml-labs/tree/master/labs/DLFramework)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Prepare data (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (3613, 500)\n",
      "y_train.shape:  (3613,)\n",
      "X_test.shape:  (347, 500)\n",
      "y_test.shape:  (347,)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# standardize name (X, y) \n",
    "X_train = BOW_500.transform(train_df['text'])\n",
    "y_train = train_df['emotion']\n",
    "\n",
    "X_test = BOW_500.transform(test_df['text'])\n",
    "y_test = test_df['emotion']\n",
    "\n",
    "## check dimension is a good habbit \n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('y_test.shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Deal with categorical label (y)\n",
    "\n",
    "Rather than put your label `train_df['emotion']` directly into a model, we have to process these categorical (or say nominal) label by ourselves. \n",
    "\n",
    "Here, we use the basic method [one-hot encoding](https://en.wikipedia.org/wiki/One-hot) to transform our categorical  labels to numerical ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://exerror.com/found-conflicts-looking-for-incompatible-packages-this-can-take-several-minutes-press-ctrl-c-to-abort/\n",
    "# https://www.codenong.com/cs122153985/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['anger' 'fear' 'joy' 'sadness']\n",
      "\n",
      "## Before convert\n",
      "y_train[0:4]:\n",
      " 3297    sadness\n",
      "832       anger\n",
      "94        anger\n",
      "322       anger\n",
      "Name: emotion, dtype: object\n",
      "\n",
      "y_train.shape:  (3613,)\n",
      "y_test.shape:  (347,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:4]:\n",
      " [[0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]]\n",
      "\n",
      "y_train.shape:  (3613, 4)\n",
      "y_test.shape:  (347, 4)\n"
     ]
    }
   ],
   "source": [
    "## deal with label (string -> one-hot)\n",
    "# https://blog.csdn.net/MSJ_nb/article/details/117462928\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    #return keras.utils.to_categorical(enc)\n",
    "    y_train = np_utils.to_categorical(enc)\n",
    "    return y_train\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  500\n",
      "output_shape:  4\n"
     ]
    }
   ],
   "source": [
    "# I/O check\n",
    "input_shape = X_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imgur](pics/pic2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 500)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                32064     \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      " softmax_1 (Softmax)         (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,484\n",
      "Trainable params: 36,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax\n",
    "\n",
    "# input layer\n",
    "model_input = Input(shape=(input_shape, ))  # 500\n",
    "X = model_input\n",
    "\n",
    "# 1st hidden layer\n",
    "X_W1 = Dense(units=64)(X)  # 64\n",
    "H1 = ReLU()(X_W1)\n",
    "\n",
    "# 2nd hidden layer\n",
    "H1_W2 = Dense(units=64)(H1)  # 64\n",
    "H2 = ReLU()(H1_W2)\n",
    "\n",
    "# output layer\n",
    "H2_W3 = Dense(units=output_shape)(H2)  # 4\n",
    "H3 = Softmax()(H2_W3)\n",
    "\n",
    "model_output = H3\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# loss function & optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show model construction\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "113/113 [==============================] - 1s 2ms/step - loss: 1.3203 - accuracy: 0.3706 - val_loss: 1.2571 - val_accuracy: 0.4784\n",
      "Epoch 2/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.9572 - accuracy: 0.6659 - val_loss: 0.9195 - val_accuracy: 0.6801\n",
      "Epoch 3/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.5654 - accuracy: 0.8029 - val_loss: 0.7884 - val_accuracy: 0.6974\n",
      "Epoch 4/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.4206 - accuracy: 0.8519 - val_loss: 0.7907 - val_accuracy: 0.6888\n",
      "Epoch 5/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.3314 - accuracy: 0.8835 - val_loss: 0.8288 - val_accuracy: 0.6916\n",
      "Epoch 6/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2782 - accuracy: 0.9064 - val_loss: 0.8569 - val_accuracy: 0.6859\n",
      "Epoch 7/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2338 - accuracy: 0.9203 - val_loss: 0.9390 - val_accuracy: 0.6974\n",
      "Epoch 8/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 0.9336 - val_loss: 0.9613 - val_accuracy: 0.6715\n",
      "Epoch 9/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1683 - accuracy: 0.9446 - val_loss: 0.9923 - val_accuracy: 0.6945\n",
      "Epoch 10/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1456 - accuracy: 0.9549 - val_loss: 1.0887 - val_accuracy: 0.6859\n",
      "Epoch 11/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1295 - accuracy: 0.9596 - val_loss: 1.0829 - val_accuracy: 0.6744\n",
      "Epoch 12/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.9637 - val_loss: 1.1576 - val_accuracy: 0.6715\n",
      "Epoch 13/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1102 - accuracy: 0.9651 - val_loss: 1.1726 - val_accuracy: 0.6801\n",
      "Epoch 14/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0987 - accuracy: 0.9693 - val_loss: 1.2265 - val_accuracy: 0.6772\n",
      "Epoch 15/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9684 - val_loss: 1.2530 - val_accuracy: 0.6744\n",
      "Epoch 16/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9759 - val_loss: 1.3446 - val_accuracy: 0.6859\n",
      "Epoch 17/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9726 - val_loss: 1.3722 - val_accuracy: 0.6830\n",
      "Epoch 18/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0755 - accuracy: 0.9740 - val_loss: 1.3743 - val_accuracy: 0.6859\n",
      "Epoch 19/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9745 - val_loss: 1.4098 - val_accuracy: 0.6859\n",
      "Epoch 20/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.9762 - val_loss: 1.4272 - val_accuracy: 0.6657\n",
      "Epoch 21/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0713 - accuracy: 0.9770 - val_loss: 1.4767 - val_accuracy: 0.6916\n",
      "Epoch 22/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0688 - accuracy: 0.9784 - val_loss: 1.4751 - val_accuracy: 0.6744\n",
      "Epoch 23/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0678 - accuracy: 0.9748 - val_loss: 1.5698 - val_accuracy: 0.6542\n",
      "Epoch 24/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9768 - val_loss: 1.5746 - val_accuracy: 0.6744\n",
      "Epoch 25/25\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.0588 - accuracy: 0.9803 - val_loss: 1.6160 - val_accuracy: 0.6772\n",
      "training finish\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('logs/training_log.csv')\n",
    "\n",
    "# training setting\n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "# training!\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[csv_logger],\n",
    "                    validation_data = (X_test, y_test))\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Predict on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.2307433e-06, 5.9249683e-06, 9.9998069e-01, 5.1647653e-06],\n",
       "       [3.9967181e-05, 9.9579263e-01, 1.4553624e-05, 4.1528866e-03],\n",
       "       [1.7438812e-02, 5.4951400e-01, 7.5587465e-08, 4.3304709e-01],\n",
       "       [4.8117382e-03, 9.2930228e-01, 1.6957123e-04, 6.5716498e-02],\n",
       "       [1.3541008e-04, 9.9943072e-01, 1.5033925e-06, 4.3232573e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict\n",
    "pred_result = model.predict(X_test, batch_size=128)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy', 'fear', 'fear', 'fear', 'fear'], dtype=object)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result = label_decode(label_encoder, pred_result)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('testing accuracy: {}'.format(round(accuracy_score(label_decode(label_encoder, y_test), pred_result), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.370606</td>\n",
       "      <td>1.320326</td>\n",
       "      <td>0.478386</td>\n",
       "      <td>1.257124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.665929</td>\n",
       "      <td>0.957174</td>\n",
       "      <td>0.680115</td>\n",
       "      <td>0.919471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.802934</td>\n",
       "      <td>0.565384</td>\n",
       "      <td>0.697406</td>\n",
       "      <td>0.788420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.851924</td>\n",
       "      <td>0.420630</td>\n",
       "      <td>0.688761</td>\n",
       "      <td>0.790685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.883476</td>\n",
       "      <td>0.331404</td>\n",
       "      <td>0.691643</td>\n",
       "      <td>0.828760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.906449</td>\n",
       "      <td>0.278154</td>\n",
       "      <td>0.685879</td>\n",
       "      <td>0.856853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.920288</td>\n",
       "      <td>0.233822</td>\n",
       "      <td>0.697406</td>\n",
       "      <td>0.939042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.933573</td>\n",
       "      <td>0.202340</td>\n",
       "      <td>0.671470</td>\n",
       "      <td>0.961317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.944644</td>\n",
       "      <td>0.168270</td>\n",
       "      <td>0.694524</td>\n",
       "      <td>0.992334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.954885</td>\n",
       "      <td>0.145576</td>\n",
       "      <td>0.685879</td>\n",
       "      <td>1.088652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.959590</td>\n",
       "      <td>0.129530</td>\n",
       "      <td>0.674352</td>\n",
       "      <td>1.082898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.963742</td>\n",
       "      <td>0.119180</td>\n",
       "      <td>0.671470</td>\n",
       "      <td>1.157571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.965126</td>\n",
       "      <td>0.110250</td>\n",
       "      <td>0.680115</td>\n",
       "      <td>1.172635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.969278</td>\n",
       "      <td>0.098665</td>\n",
       "      <td>0.677233</td>\n",
       "      <td>1.226512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.968447</td>\n",
       "      <td>0.100190</td>\n",
       "      <td>0.674352</td>\n",
       "      <td>1.252974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.975920</td>\n",
       "      <td>0.078548</td>\n",
       "      <td>0.685879</td>\n",
       "      <td>1.344550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.972599</td>\n",
       "      <td>0.084760</td>\n",
       "      <td>0.682997</td>\n",
       "      <td>1.372158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.973983</td>\n",
       "      <td>0.075530</td>\n",
       "      <td>0.685879</td>\n",
       "      <td>1.374348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.974536</td>\n",
       "      <td>0.078510</td>\n",
       "      <td>0.685879</td>\n",
       "      <td>1.409768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.976197</td>\n",
       "      <td>0.076767</td>\n",
       "      <td>0.665706</td>\n",
       "      <td>1.427215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.977027</td>\n",
       "      <td>0.071323</td>\n",
       "      <td>0.691643</td>\n",
       "      <td>1.476730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.978411</td>\n",
       "      <td>0.068844</td>\n",
       "      <td>0.674352</td>\n",
       "      <td>1.475096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.974813</td>\n",
       "      <td>0.067760</td>\n",
       "      <td>0.654179</td>\n",
       "      <td>1.569811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.976751</td>\n",
       "      <td>0.066474</td>\n",
       "      <td>0.674352</td>\n",
       "      <td>1.574565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.980349</td>\n",
       "      <td>0.058843</td>\n",
       "      <td>0.677233</td>\n",
       "      <td>1.616009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  accuracy      loss  val_accuracy  val_loss\n",
       "0       0  0.370606  1.320326      0.478386  1.257124\n",
       "1       1  0.665929  0.957174      0.680115  0.919471\n",
       "2       2  0.802934  0.565384      0.697406  0.788420\n",
       "3       3  0.851924  0.420630      0.688761  0.790685\n",
       "4       4  0.883476  0.331404      0.691643  0.828760\n",
       "5       5  0.906449  0.278154      0.685879  0.856853\n",
       "6       6  0.920288  0.233822      0.697406  0.939042\n",
       "7       7  0.933573  0.202340      0.671470  0.961317\n",
       "8       8  0.944644  0.168270      0.694524  0.992334\n",
       "9       9  0.954885  0.145576      0.685879  1.088652\n",
       "10     10  0.959590  0.129530      0.674352  1.082898\n",
       "11     11  0.963742  0.119180      0.671470  1.157571\n",
       "12     12  0.965126  0.110250      0.680115  1.172635\n",
       "13     13  0.969278  0.098665      0.677233  1.226512\n",
       "14     14  0.968447  0.100190      0.674352  1.252974\n",
       "15     15  0.975920  0.078548      0.685879  1.344550\n",
       "16     16  0.972599  0.084760      0.682997  1.372158\n",
       "17     17  0.973983  0.075530      0.685879  1.374348\n",
       "18     18  0.974536  0.078510      0.685879  1.409768\n",
       "19     19  0.976197  0.076767      0.665706  1.427215\n",
       "20     20  0.977027  0.071323      0.691643  1.476730\n",
       "21     21  0.978411  0.068844      0.674352  1.475096\n",
       "22     22  0.974813  0.067760      0.654179  1.569811\n",
       "23     23  0.976751  0.066474      0.674352  1.574565\n",
       "24     24  0.980349  0.058843      0.677233  1.616009"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's take a look at the training log\n",
    "training_log = pd.DataFrame()\n",
    "training_log = pd.read_csv(\"logs/training_log.csv\")\n",
    "training_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 6 (Take home): **  \n",
    "\n",
    "Plot the Training and Validation Accuracy and Loss (different plots), just like the images below (Note: the pictures below are an example from a different model). How to interpret the graphs you got? How are they related to the concept of overfitting/underfitting covered in class?\n",
    "<table><tr>\n",
    "    <td><img src=\"pics/pic3.png\" style=\"width: 300px;\"/> </td>\n",
    "    <td><img src=\"pics/pic4.png\" style=\"width: 300px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer here\n",
    "# https://stackoverflow.com/questions/42818361/how-to-make-two-plots-side-by-side-using-python/42818547\n",
    "# https://vimsky.com/zh-tw/examples/usage/matplotlib-pyplot-legend-in-python.html\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#plt.figure(figsize=(8,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.legend([\"accuracy\", \"val_accuracy\"], loc='lower right')\n",
    "plt.title(\"Training Accuracy per epoch\") # title\n",
    "plt.ylabel(\"Accurary\") # y label\n",
    "plt.xlabel(\"Epochs\") # x label\n",
    "plt.plot(training_log.epoch,training_log.accuracy, color=(255/255,100/255,100/255),label = \"accuracy\") #red \n",
    "plt.plot(training_log.epoch,training_log.val_accuracy, color=(100/255,100/255,255/255), label = \"val_accuracy\") #blue\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "\n",
    "plt.title(\"Training Loss per epoch\") # title\n",
    "plt.ylabel(\"Accurary\") # y label\n",
    "plt.xlabel(\"Epochs\") # x label\n",
    "\n",
    "plt.plot(training_log.epoch,training_log.loss, color=(255/255,100/255,100/255), label = \"loss\") #red\n",
    "plt.plot(training_log.epoch,training_log.val_loss, color=(100/255,100/255,255/255), label = \"val_loss\") #blue\n",
    "plt.legend()\n",
    "\n",
    "# https://www.delftstack.com/zh-tw/howto/matplotlib/how-to-improve-subplot-size-or-spacing-with-many-subplots-in-matplotlib/#plt.subplots_adjust-%25E6%2596%25B9%25E6%25B3%2595%25E6%259B%25B4%25E6%2594%25B9-matplotlib-%25E5%25AD%2590%25E5%259C%2596%25E9%2596%2593%25E8%25B7%259D\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.show()\n",
    "\n",
    "# interpret \n",
    "# reference\n",
    "# https://www.cxymm.net/searchArticle?qc=val%20loss%E5%85%88%E4%B8%8B%E9%99%8D%E5%90%8E%E4%B8%8A%E5%8D%87&page=1\n",
    "\n",
    "# Let's see the picture of training accuracy per epoch.\n",
    "# As figure shows, the accuracy is higer and higher with the epochs going.\n",
    "# The accuracy is even close to 1.\n",
    "# However, the validation accuracy peaks at the 2nd or 3rd epoch and slightly decreses.\n",
    "\n",
    "# Let's see the other picture of training loss per epoch.\n",
    "# the training loss keep decresing and close to 0.1.\n",
    "# However, the validation loss decreases before around the 3th epoch and increases after the 4th epoch.\n",
    "\n",
    "# overfitting: perform well in training dataset but poorly in validation dataset.\n",
    "# underfitting: perform poorly in both training dataset and validation dataset.\n",
    "\n",
    "# Therefore, we can learn that this is \"overfitting\" because the plot matches the overfitting situation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "\n",
    "If you don't have a GPU (level is higher than GTX 1060) or you are not good at setting lots of things about computer, we recommend you to use the [kaggle kernel](https://www.kaggle.com/kernels) to do deep learning model training. They have already installed all the librarys and provided free GPU for you to use.\n",
    "\n",
    "Note however that you will only be able to run a kernel for 6 hours. After 6 hours of inactivity, your Kaggle kernel will shut down (meaning if your model takes more than 6 hours to train, you can't train it at once).\n",
    "\n",
    "\n",
    "### More Information for your reference\n",
    "\n",
    "* Keras document: https://keras.io/\n",
    "* Keras GitHub example: https://github.com/keras-team/keras/tree/master/examples\n",
    "* CS229: Machine Learning: http://cs229.stanford.edu/syllabus.html\n",
    "* Deep Learning cheatsheet: https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning\n",
    "* If you want to try TensorFlow or PyTorch: https://pytorch.org/tutorials/\n",
    "https://www.tensorflow.org/tutorials/quickstart/beginner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Word2Vector\n",
    "\n",
    "We will introduce how to use `gensim` to train your word2vec model and how to load a pre-trained model.\n",
    "\n",
    "https://radimrehurek.com/gensim/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Prepare training corpus/訓練語料庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>40470</td>\n",
       "      <td>Shoutout to the drunk man on the bus who pisse...</td>\n",
       "      <td>[Shoutout, to, the, drunk, man, on, the, bus, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>10832</td>\n",
       "      <td>@JaredLeto Jared + #snap? 💘</td>\n",
       "      <td>[@, JaredLeto, Jared, +, #, snap, ?, 💘]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>10094</td>\n",
       "      <td>@leesyatt you are a cruel, cruel man. #therewi...</td>\n",
       "      <td>[@, leesyatt, you, are, a, cruel, ,, cruel, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>10322</td>\n",
       "      <td>@Darren_Hammer amen, nothing personal mate, ju...</td>\n",
       "      <td>[@, Darren_Hammer, amen, ,, nothing, personal,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>30364</td>\n",
       "      <td>Another joyful encounter in Tribez &amp;amp; Castl...</td>\n",
       "      <td>[Another, joyful, encounter, in, Tribez, &amp;, am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  \\\n",
       "3297  40470  Shoutout to the drunk man on the bus who pisse...   \n",
       "832   10832                        @JaredLeto Jared + #snap? 💘   \n",
       "94    10094  @leesyatt you are a cruel, cruel man. #therewi...   \n",
       "322   10322  @Darren_Hammer amen, nothing personal mate, ju...   \n",
       "2368  30364  Another joyful encounter in Tribez &amp; Castl...   \n",
       "\n",
       "                                         text_tokenized  \n",
       "3297  [Shoutout, to, the, drunk, man, on, the, bus, ...  \n",
       "832             [@, JaredLeto, Jared, +, #, snap, ?, 💘]  \n",
       "94    [@, leesyatt, you, are, a, cruel, ,, cruel, ma...  \n",
       "322   [@, Darren_Hammer, amen, ,, nothing, personal,...  \n",
       "2368  [Another, joyful, encounter, in, Tribez, &, am...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check library\n",
    "import gensim\n",
    "\n",
    "## ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# # if you want to see the training messages, you can use it\n",
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "## the input type\n",
    "train_df['text_tokenized'] = train_df['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "train_df[['id', 'text', 'text_tokenized']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['Shoutout', 'to', 'the', 'drunk', 'man', 'on', 'the', 'bus', 'who', 'pissed', 'in', 'a', 'bottle', 'and', 'on', 'the', 'seats']),\n",
       "       list(['@', 'JaredLeto', 'Jared', '+', '#', 'snap', '?', '💘']),\n",
       "       list(['@', 'leesyatt', 'you', 'are', 'a', 'cruel', ',', 'cruel', 'man', '.', '#', 'therewillbeblood'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create the training corpus\n",
    "training_corpus = train_df['text_tokenized'].values\n",
    "training_corpus[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Training our model\n",
    "\n",
    "You can try to train your own model. More details: https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>40470</td>\n",
       "      <td>Shoutout to the drunk man on the bus who pisse...</td>\n",
       "      <td>[Shoutout, to, the, drunk, man, on, the, bus, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>10832</td>\n",
       "      <td>@JaredLeto Jared + #snap? 💘</td>\n",
       "      <td>[@, JaredLeto, Jared, +, #, snap, ?, 💘]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>10094</td>\n",
       "      <td>@leesyatt you are a cruel, cruel man. #therewi...</td>\n",
       "      <td>[@, leesyatt, you, are, a, cruel, ,, cruel, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>10322</td>\n",
       "      <td>@Darren_Hammer amen, nothing personal mate, ju...</td>\n",
       "      <td>[@, Darren_Hammer, amen, ,, nothing, personal,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>30364</td>\n",
       "      <td>Another joyful encounter in Tribez &amp;amp; Castl...</td>\n",
       "      <td>[Another, joyful, encounter, in, Tribez, &amp;, am...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  \\\n",
       "3297  40470  Shoutout to the drunk man on the bus who pisse...   \n",
       "832   10832                        @JaredLeto Jared + #snap? 💘   \n",
       "94    10094  @leesyatt you are a cruel, cruel man. #therewi...   \n",
       "322   10322  @Darren_Hammer amen, nothing personal mate, ju...   \n",
       "2368  30364  Another joyful encounter in Tribez &amp; Castl...   \n",
       "\n",
       "                                         text_tokenized  \n",
       "3297  [Shoutout, to, the, drunk, man, on, the, bus, ...  \n",
       "832             [@, JaredLeto, Jared, +, #, snap, ?, 💘]  \n",
       "94    [@, leesyatt, you, are, a, cruel, ,, cruel, ma...  \n",
       "322   [@, Darren_Hammer, amen, ,, nothing, personal,...  \n",
       "2368  [Another, joyful, encounter, in, Tribez, &, am...  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the input type\n",
    "train_df['text_tokenized'] = train_df['text'].apply(lambda x: nltk.word_tokenize(x))\n",
    "train_df[['id', 'text', 'text_tokenized']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "## setting\n",
    "vector_dim = 100\n",
    "window_size = 5\n",
    "min_count = 1\n",
    "training_iter = 20\n",
    "\n",
    "# https://blog.csdn.net/lcy6239/article/details/115786432\n",
    "# size-> vector_size\n",
    "# iter-> epochs\n",
    "## model\n",
    "word2vec_model = Word2Vec(sentences=training_corpus, \n",
    "                          vector_size=vector_dim, window=window_size, \n",
    "                          min_count=min_count, epochs=training_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imgur](https://i.imgur.com/Fca3MCs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Generating word vector (embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.5284106e-01,  4.3842500e-01,  2.1559520e-01,  2.9542458e-01,\n",
       "       -1.5141673e-01, -1.5835193e+00,  5.8175814e-01,  1.6577860e+00,\n",
       "       -4.9572843e-01, -6.1560839e-01, -2.7003491e-01, -1.1354388e+00,\n",
       "       -8.1263423e-01,  1.7284940e-01, -6.5245539e-02, -6.0779315e-01,\n",
       "        3.1472486e-01, -7.6043963e-01,  3.4863365e-01, -8.5246903e-01,\n",
       "        3.6974156e-01,  8.1484020e-01,  4.5508254e-01,  3.3940154e-01,\n",
       "        4.2213374e-01, -4.4707149e-02, -1.0207807e+00,  5.2756226e-01,\n",
       "       -2.0671053e-01, -2.9877216e-02,  2.9991397e-01, -3.8291830e-01,\n",
       "        5.1755148e-01, -5.6657994e-01, -3.9636409e-01,  5.1458687e-01,\n",
       "        6.1524594e-01, -1.1859336e-01, -3.6667952e-01, -4.1063613e-01,\n",
       "        2.7790812e-01,  3.3954996e-01, -3.6054167e-01,  2.8014395e-01,\n",
       "        5.5758119e-01, -2.1808036e-01, -1.0391442e+00,  1.9035572e-01,\n",
       "        4.6839297e-01,  1.6309601e-01,  1.1557671e-01, -3.0704916e-01,\n",
       "        7.9915404e-01, -2.2763057e-01, -4.1896281e-01, -3.2925302e-01,\n",
       "       -7.4966080e-02, -5.0675005e-02,  5.7437181e-02,  4.5310814e-02,\n",
       "       -1.5207952e-01,  1.6994539e-01,  4.1274026e-01,  6.6996487e-03,\n",
       "       -3.4268254e-01,  3.2420146e-01,  3.2280359e-01,  7.2264063e-01,\n",
       "       -1.3259441e+00,  3.7791777e-01, -2.3153326e-01,  3.8925415e-01,\n",
       "        5.5180490e-01, -5.0562721e-01,  6.1135596e-01, -1.6920824e-01,\n",
       "        5.8623260e-01, -2.5677124e-01, -4.7403800e-01,  5.1741630e-02,\n",
       "       -1.0104480e+00, -3.5958609e-01, -3.3737534e-01,  1.1576117e+00,\n",
       "       -1.0913708e-01, -4.8818597e-01,  3.9757037e-01, -1.1761258e-03,\n",
       "       -1.5607671e-01,  2.9827139e-01,  7.6291507e-01,  1.0375590e-01,\n",
       "        6.5212977e-01, -2.1922925e-02,  1.3513020e+00,  2.7247652e-01,\n",
       "       -2.0117450e-01,  4.0006872e-02,  1.5239523e-01, -7.5648315e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the corresponding vector of a word\n",
    "word_vec = word2vec_model.wv['happy']\n",
    "word_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('successful', 0.9090874791145325),\n",
       " ('birthday', 0.8981354832649231),\n",
       " ('Be', 0.8964048624038696),\n",
       " (\"'be\", 0.8960666060447693),\n",
       " ('Really', 0.8912182450294495),\n",
       " ('smile', 0.886875569820404),\n",
       " ('blessing', 0.885566771030426),\n",
       " ('blessed', 0.8854401707649231),\n",
       " ('promise', 0.8783951997756958),\n",
       " ('en-route', 0.8758323788642883)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the most similar words\n",
    "# https://github.com/RaRe-Technologies/gensim/issues/3028\n",
    "word = 'happy'\n",
    "topn = 10\n",
    "word2vec_model.wv.most_similar(word, topn=topn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 Using a pre-trained w2v model\n",
    "\n",
    "Instead of training your own model ,you can use a model that has already been trained. Here, we see 2 ways of doing that:\n",
    "\n",
    "\n",
    "#### (1) Download model by yourself\n",
    "\n",
    "source: [GoogleNews-vectors-negative300](https://code.google.com/archive/p/word2vec/)\n",
    "\n",
    "more details: https://radimrehurek.com/gensim/models/keyedvectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('glad', 0.7408890724182129),\n",
       " ('pleased', 0.6632170677185059),\n",
       " ('ecstatic', 0.6626912355422974),\n",
       " ('overjoyed', 0.6599286794662476),\n",
       " ('thrilled', 0.6514049172401428),\n",
       " ('satisfied', 0.6437949538230896),\n",
       " ('proud', 0.636042058467865),\n",
       " ('delighted', 0.6272379159927368),\n",
       " ('disappointed', 0.6269949674606323),\n",
       " ('excited', 0.6247665882110596)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "## Note: this model is very huge, this will take some time ...\n",
    "model_path = \"C:/Users/Silvia/OneDrive - 清華大學/桌面/110 Fall/資料探勘/DM2021-Lab2-master-main/GoogleNews/GoogleNews-vectors-negative300.bin.gz\"\n",
    "w2v_google_model = KeyedVectors.load_word2vec_format(model_path, binary=True)\n",
    "print('load ok')\n",
    "\n",
    "w2v_google_model.most_similar('happy', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) Using gensim api\n",
    "\n",
    "Other pretrained models are available here: https://github.com/RaRe-Technologies/gensim-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ok\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('birthday', 0.9577818512916565),\n",
       " ('thank', 0.937666654586792),\n",
       " ('welcome', 0.93361496925354),\n",
       " ('love', 0.917618453502655),\n",
       " ('miss', 0.9164499640464783),\n",
       " ('hello', 0.9158352017402649),\n",
       " ('thanks', 0.9150084853172302),\n",
       " ('merry', 0.9053248167037964),\n",
       " ('bless', 0.902732253074646),\n",
       " ('wish', 0.9013165235519409)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "## If you see `SSL: CERTIFICATE_VERIFY_FAILED` error, use this:\n",
    "import ssl\n",
    "import urllib.request\n",
    "ssl._create_default_https_context = ssl._create_unverified_context #python做爬蟲，對於有的網站需要驗證\n",
    "\n",
    "glove_twitter_25_model = api.load(\"glove-twitter-25\")\n",
    "print('load ok')\n",
    "\n",
    "glove_twitter_25_model.most_similar('happy', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 king + woman - man = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run one of the most famous examples for Word2Vec and compute the similarity between these 3 words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674735069275),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321243286133),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.518113374710083),\n",
       " ('sultan', 0.5098593831062317),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_google_model.most_similar(positive=['king', 'woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 7 (Take home): **  \n",
    "\n",
    "Now, we have the word vectors, but our input data is a sequence of words (or say sentence). \n",
    "How can we utilize these \"word\" vectors to represent the sentence data and train our model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer here\n",
    "train_df['text_tokenized']\n",
    "\n",
    "1. convert the text_tokenized into word vectors.\n",
    "2. convert word vector into setence vectors.\n",
    "transformation of word vectors into sentence vectors. How to do? Google it. Not Pandas.\n",
    "3. train the model with the setence vectors. (just like exercise 6)\n",
    "\n",
    "#### I use doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://clay-atlas.com/blog/2020/07/14/python-cn-nlp-gensim-doc2vec-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import doc2vec\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "docs = []\n",
    "analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')\n",
    "for index, text in enumerate(train_df['text']):\n",
    "    words = text.split()\n",
    "    print(words)\n",
    "    docs.append(analyzedDocument(words, [index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train \n",
    "model = doc2vec.Doc2Vec(docs, size=300, window=300, min_count=1, workers=4, dm=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(total_examples=model.corpus_count,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_sent_2_d2v = model.infer_vector(exp_sent_2_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vec_sent_2_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把emoji變成::xxxxx::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train_df['text_tokenized'] to 1-D list\n",
    "#from itertools import chain\n",
    "#token = []\n",
    "#token = list(train_df['text_tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.csdn.net/weixin_45459224/article/details/105855545\n",
    "# let demojize into ::xxx:::\n",
    "#train_list = []\n",
    "#\n",
    "#import emoji\n",
    "#\n",
    "#for i in range(len(token)):\n",
    "#    temp = []\n",
    "#    for j in range(len(token[i])):\n",
    "#        temp.append(emoji.demojize(token[i][j]))\n",
    "#    train_list.append(temp)\n",
    "    \n",
    "#np.shape(train_list)\n",
    "#train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = []\n",
    "#for i in range(len(train_list)):\n",
    "#    temp = []\n",
    "#    for j in range(len(train_list[i])):\n",
    "#        if train_list[i][j] in punctuation or \":\" in train_list[i][j]:\n",
    "#            train_list[i][j] = None           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kite.com/python/answers/how-to-remove-none-from-a-list-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp = []\n",
    "#for i in range(len(train_list)):\n",
    "#    train_list[i] = list(filter(None.__ne__, train_list[i]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Word2Vec(train_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Clustering: k-means\n",
    "\n",
    "Here we introduce how to use `sklearn` to do the basic **unsupervised learning** approach, k-means.    \n",
    "\n",
    "more details: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic concept\n",
    "\n",
    "![Image](https://i.imgur.com/PEdUf54.png)\n",
    "\n",
    "(img source: https://towardsdatascience.com/k-means-clustering-identifying-f-r-i-e-n-d-s-in-the-world-of-strangers-695537505d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clustering target\n",
    "target_list = ['happy', 'fear', 'angry', 'car', 'teacher', 'computer']\n",
    "print('target words: ', target_list)\n",
    "\n",
    "# convert to word vector\n",
    "X = [word2vec_model.wv[word] for word in target_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# we have to decide how many cluster (k) we want\n",
    "k = 2\n",
    "\n",
    "# k-means model\n",
    "kmeans_model = KMeans(n_clusters=k)\n",
    "kmeans_model.fit(X)\n",
    "\n",
    "# cluster result\n",
    "cluster_result = kmeans_model.labels_\n",
    "\n",
    "# show\n",
    "for i in range(len(target_list)):\n",
    "    print('word: {} \\t cluster: {}'.format(target_list[i], cluster_result[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Imgur](pics/pic6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check cluster membership\n",
    "word = 'student'\n",
    "word_vec = word2vec_model.wv[word]\n",
    "kmeans_model.predict([word_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check cluster membership\n",
    "word = 'sad'\n",
    "word_vec = word2vec_model.wv[word]\n",
    "kmeans_model.predict([word_vec])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 9. High-dimension Visualization: t-SNE\n",
    "\n",
    "No matter if you use the Bag-of-words, tf-idf, or word2vec, it's very hard to see the embedding result, because the dimension is larger than 3.  \n",
    "\n",
    "In Lab 1, we already talked about PCA. We can use PCA to reduce the dimension of our data, then visualize it. However, if you dig deeper into the result, you'd find it is insufficient...\n",
    "\n",
    "Our aim will be to create a visualization similar to the one below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](pics/pic7.png)\n",
    "source: https://www.fabian-keller.de/research/high-dimensional-data-visualization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we would like to introduce another visualization method called t-SNE.  \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Prepare visualizing target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repare data lists like:\n",
    "    - happpy words\n",
    "    - angry words\n",
    "    - data words\n",
    "    - mining words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_list = ['happy', 'angry', 'data', 'mining']\n",
    "\n",
    "topn = 5\n",
    "happy_words = ['happy'] + [word_ for word_, sim_ in w2v_google_model.most_similar('happy', topn=topn)]\n",
    "angry_words = ['angry'] + [word_ for word_, sim_ in w2v_google_model.most_similar('angry', topn=topn)]        \n",
    "data_words = ['data'] + [word_ for word_, sim_ in w2v_google_model.most_similar('data', topn=topn)]        \n",
    "mining_words = ['mining'] + [word_ for word_, sim_ in w2v_google_model.most_similar('mining', topn=topn)]        \n",
    "\n",
    "print('happy_words: ', happy_words)\n",
    "print('angry_words: ', angry_words)\n",
    "print('data_words: ', data_words)\n",
    "print('mining_words: ', mining_words)\n",
    "\n",
    "target_words = happy_words + angry_words + data_words + mining_words\n",
    "print('\\ntarget words: ')\n",
    "print(target_words)\n",
    "\n",
    "print('\\ncolor list:')\n",
    "cn = topn + 1\n",
    "color = ['b'] * cn + ['g'] * cn + ['r'] * cn + ['y'] * cn\n",
    "print(color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Plot using t-SNE (2-dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "## w2v model\n",
    "model = w2v_google_model\n",
    "\n",
    "## prepare training word vectors\n",
    "size = 200\n",
    "target_size = len(target_words)\n",
    "# https://stackoverflow.com/questions/66868221/gensim-3-8-0-to-gensim-4-0-0\n",
    "# all_word = list(model.vocab.keys())\n",
    "all_word = list(model.index_to_key)\n",
    "word_train = target_words + all_word[:size]\n",
    "X_train = model[word_train]\n",
    "\n",
    "## t-SNE model\n",
    "tsne = TSNE(n_components=2, metric='cosine', random_state=28)\n",
    "\n",
    "## training\n",
    "X_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "## plot the result\n",
    "plt.figure(figsize=(7.5, 7.5), dpi=115)\n",
    "plt.scatter(X_tsne[:target_size, 0], X_tsne[:target_size, 1], c=color)\n",
    "for label, x, y in zip(target_words, X_tsne[:target_size, 0], X_tsne[:target_size, 1]):\n",
    "    plt.annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### ** >>> Exercise 8 (Take home): **  \n",
    "\n",
    "Generate a t-SNE visualization to show the 15 words most related to the words \"angry\", \"happy\", \"sad\", \"fear\" (60 words total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_list = ['angry', 'happy', 'sad', 'fear']\n",
    "\n",
    "topn = 14 # 0~14: total 15\n",
    "angry_words = ['angry'] + [word_ for word_, sim_ in w2v_google_model.most_similar('angry', topn=topn)]\n",
    "happy_words = ['happy'] + [word_ for word_, sim_ in w2v_google_model.most_similar('happy', topn=topn)]        \n",
    "sad_words = ['sad'] + [word_ for word_, sim_ in w2v_google_model.most_similar('sad', topn=topn)]        \n",
    "fear_words = ['fear'] + [word_ for word_, sim_ in w2v_google_model.most_similar('fear', topn=topn)]        \n",
    "\n",
    "print('angry_words: ', angry_words)\n",
    "print('happy_words: ', happy_words)\n",
    "print('sad_words: ', sad_words)\n",
    "print('fear_words: ', fear_words)\n",
    "\n",
    "target_words_ = angry_words + happy_words + sad_words + fear_words\n",
    "print('\\ntarget words: ')\n",
    "print(target_words_)\n",
    "\n",
    "print('\\ncolor list:')\n",
    "cn = topn + 1\n",
    "color = ['b'] * cn + ['g'] * cn + ['r'] * cn + ['y'] * cn\n",
    "print(color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "## w2v model\n",
    "model = w2v_google_model\n",
    "\n",
    "## prepare training word vectors\n",
    "size = 2000\n",
    "target_size = len(target_words_)\n",
    "# https://stackoverflow.com/questions/66868221/gensim-3-8-0-to-gensim-4-0-0\n",
    "# all_word = list(model.vocab.keys())\n",
    "all_word = list(model.index_to_key)\n",
    "word_train = target_words_ + all_word[:size]\n",
    "X_train = model[word_train]\n",
    "\n",
    "## t-SNE model\n",
    "tsne = TSNE(n_components=2, metric='cosine', random_state=28)\n",
    "\n",
    "## training\n",
    "X_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "## plot the result\n",
    "plt.figure(figsize=(7.5, 7.5), dpi=115)\n",
    "plt.scatter(X_tsne[:target_size, 0], X_tsne[:target_size, 1], c=color)\n",
    "for label, x, y in zip(target_words_, X_tsne[:target_size, 0], X_tsne[:target_size, 1]):\n",
    "    plt.annotate(label, xy=(x,y), xytext=(0,0),  textcoords='offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A report of my work developping the model for the competition \n",
    "\n",
    "(You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove emoji.\n",
    "After I read the json file, I found that there are many puctunation and emoji in the text, which we should clean from the data.\n",
    "I must remove emojis and punctuations since all we need is text only. The cell below is modified from the website, https://poopcode.com/how-to-remove-emoji-from-text-in-python/, I also use regular languages to define a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "        u\"\\U00002600-\\U000026FF\"  # Miscellaneous Symbols\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # Miscellaneous Symbols And Pictographs\n",
    "        u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # Transport and Map Symbols\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "\n",
    "\n",
    "def remove_punctuation_emoji(value):\n",
    "    value = remove_emojis(value)\n",
    "    return ''.join([c for c in value if (c not in punctuation)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "The next step is feature engineering. I construct a data structure to save the data.\n",
    "There are 6 main classes of data, including train(for train data), test(for test data), emotion_map(for 8 types of emotions), tweep_map(the encoded map), max_voc(for the length of tweep_map), max_l(for the longest list to append 0). The subclasses of trains and test are defined as their name to store the corresponding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"train\":{\n",
    "        \"<id>\":{\n",
    "            \"emotion\":\"\",\n",
    "            \"emotion_class\":1,\n",
    "            \"text\":\"\",\n",
    "            \"text_calss\":[],\n",
    "        }  \n",
    "    },\n",
    "    \"test\":{\n",
    "        \"<id>\":{\n",
    "            \"text\":\"\",\n",
    "            \"text_calss\":[],\n",
    "        },\n",
    "    },\n",
    "    \"emotion_map\":{},\n",
    "    \"tweet_map\":{},\n",
    "    \"max_voc\":1,\n",
    "    \"max_l\":1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import “tweets_DM.json”, I tried many functions because this json cannot be read directly by read_json(). In this case, and finally read the text from tweets_DM.json. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../input/dm2021-lab2-hw2/tweets_DM.json\",\"r\") as file:\n",
    "    tweets_json_list = [eval(f) for f in file.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I call function to remove punctuations and emojis from tweets’ text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_user = {u['_source'][\"tweet\"][\"tweet_id\"]:remove_punctuation_emoji(u['_source'][\"tweet\"][\"text\"]) for u in tweets_json_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import “emotion.csv”, I modified function from this website, \n",
    "https://blog.csdn.net/u013402321/article/details/80277022, to successfully read all the text from emotion.csv. I store the data as a dictionary, keys for id and values for emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "emotion = None\n",
    "with open(\"../input/dm2021-lab2-hw2/emotion.csv\",newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    _ = next(reader)\n",
    "    emotion = {rows[0]:rows[1] for rows in reader} #row[0]:key row[1]:data, dict as a key value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import “data_identification.csv”, I modified function from this website, \n",
    "https://blog.csdn.net/u013402321/article/details/80277022, to successfully read all the text from data_identification.csv. I store the data as a dictionary, keys for id and values for identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_identification = None\n",
    "\n",
    "with open(\"../input/dm2021-lab2-hw2/data_identification.csv\",newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    _ = next(reader) # iterate once to skip the first line\n",
    "    data_identification = {rows[0]: rows[1] for rows in reader} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I categorized data as two types, “train” and “test”. The data[“train”][k] stores the id whose identification is train while data[“train”][k] stores the id of the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key_to_remove = []\n",
    "for k in data[\"train\"].keys():\n",
    "    if k in tweets_user:\n",
    "        data[\"train\"][k][\"text\"] = tweets_user[k]\n",
    "    else:\n",
    "        key_to_remove.append(k)\n",
    "\n",
    "for k in key_to_remove:\n",
    "    data[\"train\"].pop(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I remove the data whose user is not in our list of “tweets_user.” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key_to_remove = []\n",
    "for k in data[\"train\"].keys():\n",
    "    if k in tweets_user:\n",
    "        data[\"train\"][k][\"text\"] = tweets_user[k]\n",
    "    else:\n",
    "        key_to_remove.append(k)\n",
    "\n",
    "for k in key_to_remove:\n",
    "    data[\"train\"].pop(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key_to_remove = []\n",
    "for k in data[\"test\"].keys():\n",
    "    if k in tweets_user:\n",
    "        data[\"test\"][k][\"text\"] = tweets_user[k]\n",
    "    else:\n",
    "        key_to_remove.append(k)\n",
    "\n",
    "for k in key_to_remove:\n",
    "    data[\"test\"].pop(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I remove the data without emotion from data[“train”]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "key_to_remove = []\n",
    "for k in data[\"train\"].keys():\n",
    "    if k in emotion:\n",
    "        data[\"train\"][k][\"emotion\"] = emotion[k]\n",
    "    else:\n",
    "        key_to_remove.append(k)\n",
    "    \n",
    "for k in key_to_remove:\n",
    "    data[\"train\"].pop(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Emotion\n",
    "Now, I make a list with the names of 8 types of emotions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_emotion = []\n",
    "\n",
    "for m in emotion.keys():\n",
    "    if emotion[m] not in class_emotion:\n",
    "        class_emotion.append(emotion[m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I create an emotion_map for encoding the emotions. The below picture is the outcome, which is identical to our expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emotion_map = {v:i for i,v in enumerate(class_emotion)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic0](img/pic1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I store each training data’s emotion to “emotion_class”(the encoded emotion) by looking up the emotion_map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in data[\"train\"].keys():\n",
    "    data[\"train\"][k][\"emotion_class\"] = emotion_map[data[\"train\"][k][\"emotion\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I store the emotion_map to the data structure, data[“emotion_map”]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"emotion_map\"] = emotion_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Text\n",
    "I use the tool tqdm to visualize data processing. I referred the literature from the website, https://clay-atlas.com/blog/2019/11/11/python-chinese-tutorial-tqdm-progress-and-ourself/, to assist me to know the remaining time. \n",
    "\n",
    "As title, I use a loop to count the frequency of words and store the outcome in the list, tweets_data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_data = {}\n",
    "for k in tqdm(tweets_user.keys()):\n",
    "    users_text_list = tweets_user[k].split(\" \")\n",
    "    for t in users_text_list:\n",
    "        t = t.lower()\n",
    "        if t not in tweets_data:\n",
    "            tweets_data[t] = 1\n",
    "        else:\n",
    "            tweets_data[t] = tweets_data[t] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After counting the frequency and I found that some meaningless strings appear a lot, including ‘\\r’, ‘\\u’, digits, words with digits and so on. Therefore, I create the list, “remove_key”, to store their keys and remove meaningless strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remove_key = []\n",
    "for k in tweets_data.keys():\n",
    "    if '\\r' in k:\n",
    "        remove_key.append(k)\n",
    "    elif r'\\u' in k:\n",
    "        remove_key.append(k)\n",
    "    elif '\"\\\"' in k:\n",
    "        remove_key.append(k)\n",
    "    elif k.isdigit():\n",
    "        remove_key.append(k)\n",
    "    elif k == '':\n",
    "        remove_key.append(k)\n",
    "    elif k[0].isdigit():\n",
    "        remove_key.append(k)\n",
    "    elif len(k)>10:\n",
    "        remove_key.append(k)\n",
    "    elif '0' in k:\n",
    "        remove_key.append(k)\n",
    "    elif '1' in k:\n",
    "        remove_key.append(k)\n",
    "    elif '2' in k:\n",
    "        remove_key.append(k)\n",
    "    elif '3' in k:\n",
    "        remove_key.append(k)\n",
    "    elif '4' in k:\n",
    "        remove_key.append(k)\n",
    "    elif '5' in k:\n",
    "        remove_key.append(k)\n",
    "    elif '6' in k:\n",
    "        remove_key.append(k)\n",
    "    elif '7' in k:\n",
    "        remove_key.append(k)\n",
    "    elif '8' in k:\n",
    "        remove_key.append(k)\n",
    "    elif '9' in k:\n",
    "        remove_key.append(k)     \n",
    "        \n",
    "for i in remove_key:\n",
    "    tweets_data.pop(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sort the tweets_data according to the frequencies of these words and store it sorted_tweets_key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted_tweets_key = sorted(tweets_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an encoded map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary, tweet_map, is an encoded map, which encode words with a number. The empty string is the first and encode as 0. I encode the rest words by a for loop with two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweet_map  = {'':0}\n",
    "for i,v in enumerate(sorted_tweets_key):\n",
    "    tweet_map[v] = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable, l_max, is to store the longest length. The cell below is to find the list with the longest strength. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l_max = 0\n",
    "for k in tqdm(tweets_user.keys()):\n",
    "    users_text_list = tweets_user[k].split(\" \")\n",
    "    embedded_text = []\n",
    "    for t in users_text_list:\n",
    "        t = t.lower()\n",
    "        if t in tweet_map:\n",
    "            embedded_text.append(tweet_map[t])\n",
    "    if len(embedded_text)>l_max:\n",
    "        l_max = len(embedded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append 0 to those lists and store the embebbed_text into the data structure we defined, data[“train”][index][“text_class”]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in tqdm(data[\"train\"].keys()):\n",
    "    users_text_list = data[\"train\"][k][\"text\"].split(\" \")\n",
    "    embedded_text = []\n",
    "    for t in users_text_list:\n",
    "        t = t.lower()\n",
    "        if t in tweet_map:\n",
    "            embedded_text.append(tweet_map[t])\n",
    "    while len(embedded_text)<l_max:\n",
    "        embedded_text.append(0)\n",
    "    data[\"train\"][k][\"text_class\"] = embedded_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append 0 to those lists and store the embebbed_text into the data structure we defined, data[“test”][index][“text_class”]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in tqdm(data[\"test\"].keys()):\n",
    "    users_text_list = data[\"test\"][k][\"text\"].split(\" \")\n",
    "    embedded_text = []\n",
    "    for t in users_text_list:\n",
    "        t = t.lower()\n",
    "        if t in tweet_map:\n",
    "            embedded_text.append(tweet_map[t])\n",
    "    while len(embedded_text)<l_max:\n",
    "        embedded_text.append(0)\n",
    "    data[\"test\"][k][\"text_class\"] = embedded_tex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the picture, we assume that the text is **but sometimes the hurt last instead**, and we encode this word. But we our longest embedded_text is 118, which means we need to append 0 for the rest of the list. We do this in each text, called encoding the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic0](img/pic2.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic0](img/pic3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the tweet_map, the length of the tweet_map, and 118 into the data structure we defined, data[“tweet_map”], data[“max_voc”], and data[“max_l”]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"tweet_map\"] = tweet_map\n",
    "data[\"max_voc\"] = len(tweet_map)\n",
    "data[\"max_l\"] = l_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaination of my model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use LSTM(Long short-term memory) model from Pytorch. The reason why I use this model is because LSTM model is most **recommended** when it comes to sentiment analysis. Moreover, the training consumes too much time so I only training once and store the result as a .pt file. I screenshot and post here because I delete all the training part of my model.\n",
    "\n",
    "According to literature, here are pros in terms of LSTM model.\n",
    "LSTM is great technique for sentiment analysis. Since the meaning of a word has dependencies on the ones that preceded it. This improved NLP a lot and narrative analysis to leverage Neural Networks.\n",
    "\n",
    "LSTM can be used for text generation. You can train the model on the text of a writer, say, and the model will be able to generate new sentences that mimics the style and interests of the writer.\n",
    "\n",
    "Sequence-to-Sequence LSTM models are the state of the technique for translations. They also have a wide array of applications like time series forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a class to train the data. There are three functions required, including __init__(), __len__(), __getitem__()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic0](img/pic4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the data, I use LSTM model. I modified codes from this website, https://cnvrg.io/pytorch-lstm/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic0](img/pic5.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the reference, https://pytorch.org/tutorials/beginner/pytorch_with_examples.html, I define this train function to train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic0](img/pic6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the first GPU to train. Set the size of batch is 4. According to my experiences, I set learning rate(LR) 0.001 and epoch 4. The reason why I set assign variables as these values is based on my experience. It used to have greater result in terms of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic0](img/pic7.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the list we will use when we train the data. Append data by loop. The first loop is for training data while the second one is for test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic0](img/pic8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic0](img/pic9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I divide the data into 10 shards to index the data and let DataLoader gets data from dataset according to the index.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic0](img/pic10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cells are set to train data. Load dataset to tweet_dataset and assign DataLoader with data to tweet_dataloaders. The model is LSTM_model with setting the variables. Moreover, the reason I use Adam as my optimizer is that Adam converges quicklier than other ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic0](img/pic12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start to train. I trained on my laptop for more 10 hours with CUDA and more 6 hours on Kaggle with GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic0](img/pic11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trained Data\n",
    "\n",
    "I saved the training result and upload as a dataset.\n",
    "After import torch and related libraries, I load the training result by PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "torch.load(\"../input/traineddmhw2/model_full.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "Define a class to test the data. There are three functions required, including __init__(), __len__(), __getitem__(). The below cell is the similar to the training part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TWEETDataset_test(Dataset):\n",
    "    def __init__(self, name, feature):\n",
    "        self.name = name\n",
    "        self.feature = [torch.tensor(i) for i in feature]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.name[idx], self.feature[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This script was modified from\n",
    "# https://github.com/TalwalkarLab/leaf/blob/master/models/shakespeare/stacked_lstm.py\n",
    "import torch\n",
    "\n",
    "class LSTM_model(torch.nn.Module):\n",
    "    def __init__(self, n_vocab=80, output = 10, embedding_dim=64, hidden_dim_1=256, nb_layers_1=1):\n",
    "        super(LSTM_model, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim_1 = hidden_dim_1\n",
    "\n",
    "        self.embeddings = torch.nn.Embedding(n_vocab, embedding_dim)\n",
    "        self.lstm_1 = torch.nn.LSTM(embedding_dim, hidden_dim_1, nb_layers_1)\n",
    "        self.hidden2out = torch.nn.Linear(hidden_dim_1, output)\n",
    "\n",
    "    def forward(self, seq_in):\n",
    "        embeddings = self.embeddings(seq_in.t())\n",
    "        lstm_out, h_state1 = self.lstm_1(embeddings)\n",
    "        \n",
    "        ht = lstm_out[-1]\n",
    "        out = self.hidden2out(ht)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the test function. I define this test function with reference here, https://pytorch.org/docs/stable/torch.html. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    names = []\n",
    "    predicts = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for name, data in tqdm(test_data):\n",
    "\n",
    "            data = data.to(device)\n",
    "            pred = model(data)\n",
    "            _, predicted = torch.max(pred, -1)\n",
    "            \n",
    "            names.append(name)\n",
    "            predicts.append(predicted)\n",
    "\n",
    "    return names, predicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell is **the same** as the training part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "batch_size = 4\n",
    "LR = 0.001\n",
    "epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "test_name = []\n",
    "test_x = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in data[\"train\"].keys():\n",
    "    train_x.append(data[\"train\"][k]['text_class'])\n",
    "    train_y.append(data[\"train\"][k]['emotion_class'])\n",
    "        \n",
    "for k in data[\"test\"].keys():\n",
    "    test_name.append(k)\n",
    "    test_x.append(data[\"test\"][k]['text_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_dataset = TWEETDataset_test(name=test_name, feature=test_x)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_model(n_vocab=data[\"max_voc\"], output = 8, embedding_dim=128, hidden_dim_1=256, nb_layers_1=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I call test function and we can get “id” from name and “emotion” from predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, predict = tqdm(test(model=model,test_data=test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emotion_by_class(value):\n",
    "    return list(data[\"emotion_map\"] .keys())[list(data[\"emotion_map\"].values()).index(value)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I saved the result into the list, result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result = {}\n",
    "for n,p in zip(name, predict):\n",
    "    p = p.cpu().tolist()\n",
    "    for i,v in enumerate(n):\n",
    "        result[v] = get_emotion_by_class(p[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part is submission. I modified the code from here, https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html,\n",
    "and get the output in excel format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_id = list(result.keys())\n",
    "result_values = list(result.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "save_data = pandas.DataFrame({\"id\":result_id, \"emotion\":result_values})\n",
    "save_data.to_csv(\"./Submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
